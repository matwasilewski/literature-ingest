{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43ff7001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# 1. Load BioBERT model and tokenizer (choose your variant)\n",
    "model_name = \"dmis-lab/biobert-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa6e4a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c76035fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The patient was treated with Aspirin for Hypertension.  The EGFR gene was also analyzed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "469dd180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'LABEL_0',\n",
       "  'score': np.float32(0.50278854),\n",
       "  'index': 1,\n",
       "  'word': 'The',\n",
       "  'start': 0,\n",
       "  'end': 3},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': np.float32(0.5383096),\n",
       "  'index': 2,\n",
       "  'word': 'patient',\n",
       "  'start': 4,\n",
       "  'end': 11},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.54741913),\n",
       "  'index': 3,\n",
       "  'word': 'was',\n",
       "  'start': 12,\n",
       "  'end': 15},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.5702383),\n",
       "  'index': 4,\n",
       "  'word': 'treated',\n",
       "  'start': 16,\n",
       "  'end': 23},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.59693295),\n",
       "  'index': 5,\n",
       "  'word': 'with',\n",
       "  'start': 24,\n",
       "  'end': 28},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.5077557),\n",
       "  'index': 6,\n",
       "  'word': 'As',\n",
       "  'start': 29,\n",
       "  'end': 31},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.55134845),\n",
       "  'index': 7,\n",
       "  'word': '##pi',\n",
       "  'start': 31,\n",
       "  'end': 33},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': np.float32(0.5070949),\n",
       "  'index': 8,\n",
       "  'word': '##rin',\n",
       "  'start': 33,\n",
       "  'end': 36},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.50496906),\n",
       "  'index': 9,\n",
       "  'word': 'for',\n",
       "  'start': 37,\n",
       "  'end': 40},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.50271547),\n",
       "  'index': 10,\n",
       "  'word': 'H',\n",
       "  'start': 41,\n",
       "  'end': 42},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.5538823),\n",
       "  'index': 11,\n",
       "  'word': '##yper',\n",
       "  'start': 42,\n",
       "  'end': 46},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': np.float32(0.5025539),\n",
       "  'index': 12,\n",
       "  'word': '##tens',\n",
       "  'start': 46,\n",
       "  'end': 50},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.5739931),\n",
       "  'index': 13,\n",
       "  'word': '##ion',\n",
       "  'start': 50,\n",
       "  'end': 53},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.5274518),\n",
       "  'index': 14,\n",
       "  'word': '.',\n",
       "  'start': 53,\n",
       "  'end': 54},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.57909656),\n",
       "  'index': 15,\n",
       "  'word': 'The',\n",
       "  'start': 56,\n",
       "  'end': 59},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.5167905),\n",
       "  'index': 16,\n",
       "  'word': 'E',\n",
       "  'start': 60,\n",
       "  'end': 61},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.5149721),\n",
       "  'index': 17,\n",
       "  'word': '##G',\n",
       "  'start': 61,\n",
       "  'end': 62},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': np.float32(0.5270781),\n",
       "  'index': 18,\n",
       "  'word': '##F',\n",
       "  'start': 62,\n",
       "  'end': 63},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': np.float32(0.5095633),\n",
       "  'index': 19,\n",
       "  'word': '##R',\n",
       "  'start': 63,\n",
       "  'end': 64},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.5450334),\n",
       "  'index': 20,\n",
       "  'word': 'gene',\n",
       "  'start': 65,\n",
       "  'end': 69},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.5743742),\n",
       "  'index': 21,\n",
       "  'word': 'was',\n",
       "  'start': 70,\n",
       "  'end': 73},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.5982121),\n",
       "  'index': 22,\n",
       "  'word': 'also',\n",
       "  'start': 74,\n",
       "  'end': 78},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': np.float32(0.5704201),\n",
       "  'index': 23,\n",
       "  'word': 'analyzed',\n",
       "  'start': 79,\n",
       "  'end': 87},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': np.float32(0.5457792),\n",
       "  'index': 24,\n",
       "  'word': '.',\n",
       "  'start': 87,\n",
       "  'end': 88}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipeline(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefe2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_results = ner_pipeline(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c0102f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'LABEL_0', 'score': np.float32(0.50278854), 'index': 1, 'word': 'The', 'start': 0, 'end': 3}\n",
      "{'entity': 'LABEL_0', 'score': np.float32(0.5383096), 'index': 2, 'word': 'patient', 'start': 4, 'end': 11}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.54741913), 'index': 3, 'word': 'was', 'start': 12, 'end': 15}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.5702383), 'index': 4, 'word': 'treated', 'start': 16, 'end': 23}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.59693295), 'index': 5, 'word': 'with', 'start': 24, 'end': 28}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.5077557), 'index': 6, 'word': 'As', 'start': 29, 'end': 31}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.55134845), 'index': 7, 'word': '##pi', 'start': 31, 'end': 33}\n",
      "{'entity': 'LABEL_0', 'score': np.float32(0.5070949), 'index': 8, 'word': '##rin', 'start': 33, 'end': 36}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.50496906), 'index': 9, 'word': 'for', 'start': 37, 'end': 40}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.50271547), 'index': 10, 'word': 'H', 'start': 41, 'end': 42}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.5538823), 'index': 11, 'word': '##yper', 'start': 42, 'end': 46}\n",
      "{'entity': 'LABEL_0', 'score': np.float32(0.5025539), 'index': 12, 'word': '##tens', 'start': 46, 'end': 50}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.5739931), 'index': 13, 'word': '##ion', 'start': 50, 'end': 53}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.5274518), 'index': 14, 'word': '.', 'start': 53, 'end': 54}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.57909656), 'index': 15, 'word': 'The', 'start': 56, 'end': 59}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.5167905), 'index': 16, 'word': 'E', 'start': 60, 'end': 61}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.5149721), 'index': 17, 'word': '##G', 'start': 61, 'end': 62}\n",
      "{'entity': 'LABEL_0', 'score': np.float32(0.5270781), 'index': 18, 'word': '##F', 'start': 62, 'end': 63}\n",
      "{'entity': 'LABEL_0', 'score': np.float32(0.5095633), 'index': 19, 'word': '##R', 'start': 63, 'end': 64}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.5450334), 'index': 20, 'word': 'gene', 'start': 65, 'end': 69}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.5743742), 'index': 21, 'word': 'was', 'start': 70, 'end': 73}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.5982121), 'index': 22, 'word': 'also', 'start': 74, 'end': 78}\n",
      "{'entity': 'LABEL_1', 'score': np.float32(0.5704201), 'index': 23, 'word': 'analyzed', 'start': 79, 'end': 87}\n",
      "{'entity': 'LABEL_0', 'score': np.float32(0.5457792), 'index': 24, 'word': '.', 'start': 87, 'end': 88}\n"
     ]
    }
   ],
   "source": [
    "for nr in ner_results:\n",
    "    print(nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55540f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. Text to annotate\n",
    "text = \"The patient was treated with Aspirin for Hypertension.  The EGFR gene was also analyzed.\"\n",
    "\n",
    "# 3. NER with BioBERT\n",
    "ner_results = ner_pipeline(text)\n",
    "\n",
    "# 4. Entity Linking with BioPortal (improved)\n",
    "def map_to_ontology(entity_name, ontology_id=\"MeSH\"):\n",
    "    url = f\"https://bioportal.bioontology.org/ontologies/{ontology_id}/search\"\n",
    "    params = {\"q\": entity_name, \"apikey\": \"YOUR_BIOPORTAL_API_KEY\"}  # **REPLACE with your API key**\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
    "        results = response.json()\n",
    "        if results and results[\"collection\"]:\n",
    "            best_match = results[\"collection\"][0]\n",
    "            # Improved matching (consider synonyms, definitions, etc.)\n",
    "            # For now, just return the ID:\n",
    "            return best_match[\"@id\"]\n",
    "        else:\n",
    "            return None  # No match found\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error querying BioPortal: {e}\")\n",
    "        return None\n",
    "\n",
    "# 5. Process and link the entities\n",
    "entities_to_link = []\n",
    "\n",
    "for entity in ner_results:\n",
    "    entity_type = entity[\"entity_group\"]\n",
    "    entity_text = entity[\"word\"]\n",
    "\n",
    "    # Clean up entity text (remove extra spaces, etc.)\n",
    "    entity_text = re.sub(r\"\\s+\", \" \", entity_text).strip()  # Normalize whitespace\n",
    "\n",
    "    if entity_type in (\"GENE\", \"DISEASE\", \"DRUG\"):  # Filter for relevant types\n",
    "        entities_to_link.append({\"text\": entity_text, \"type\": entity_type})\n",
    "\n",
    "for entity_info in entities_to_link:\n",
    "    concept_id = map_to_ontology(entity_info[\"text\"], \"MeSH\")  # You can change ontology here\n",
    "    print(f\"Entity: {entity_info['text']}, Type: {entity_info['type']}, Concept: {concept_id}\")\n",
    "\n",
    "# Example of further processing or output:\n",
    "annotations = []\n",
    "for entity in ner_results:\n",
    "    if entity[\"entity_group\"] in (\"GENE\", \"DISEASE\", \"DRUG\"):\n",
    "        concept_uri = map_to_ontology(entity[\"word\"], \"MeSH\")\n",
    "        annotations.append({\n",
    "            \"start\": entity[\"start\"],\n",
    "            \"end\": entity[\"end\"],\n",
    "            \"text\": entity[\"word\"],\n",
    "            \"type\": entity[\"entity_group\"],\n",
    "            \"concept_uri\": concept_uri\n",
    "        })\n",
    "\n",
    "print(\"\\nAnnotations (with character offsets and concept URIs):\")\n",
    "print(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15794d65",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
